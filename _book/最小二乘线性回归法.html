<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>Chapter 6 最小二乘线性回归法 | 数据科学导论（Introductory of Data Science）</title>

    <meta name="author" content="潘蓄林" />
  
   <meta name="description" content="2022年数据科学导论" />
   <meta name="generator" content="placeholder" />
  <meta property="og:title" content="Chapter 6 最小二乘线性回归法 | 数据科学导论（Introductory of Data Science）" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="2022年数据科学导论" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 最小二乘线性回归法 | 数据科学导论（Introductory of Data Science）" />
  
  <meta name="twitter:description" content="2022年数据科学导论" />
  
  <!-- JS -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script>
  <script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script>
    <script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet" />
    <script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script>
    <script src="libs/bs3compat-0.3.1/transition.js"></script>
    <script src="libs/bs3compat-0.3.1/tabs.js"></script>
    <script src="libs/bs3compat-0.3.1/bs3compat.js"></script>
    <link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet" />
    <script src="libs/bs4_book-1.0.0/bs4_book.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script>

  <!-- CSS -->
  <style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
    
</head>

<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book">
    <a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">数据科学导论（Introductory of Data Science）</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
      </form>

      <nav aria-label="Table of contents">
        <h2>Table of contents</h2>
        <div id="book-toc"></div>

        <div class="book-extra">
          <p><a id="book-repo" href="#">View book source <i class="fab fa-github"></i></a></li></p>
        </div>
      </nav>
    </div>
  </header>

  <main class="col-sm-12 col-md-9 col-lg-7" id="content">
<div id="最小二乘线性回归法" class="section level1" number="6">
<h1><span class="header-section-number">Chapter 6</span> 最小二乘线性回归法</h1>
<div id="相关概念" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> 相关概念</h2>
<ol style="list-style-type: decimal">
<li>因变量(Dependent variable,Y)：依赖于其它变量的变化而变化，响应变量；</li>
<li>自变量(Independent variable,X)：可以直接控制的变量，协变量；</li>
<li>有监督学习的数据表示：<span class="math inline">\(D=\{(x_1,y_1),\cdots,x_n,y_n)\},x\in R^p,y \in R\)</span>;</li>
<li>模型（model)：函数；</li>
<li>参数(Parameters)：参数是添加到模型中用于估计输出的成分;</li>
</ol>
</div>
<div id="线性模型" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> 线性模型</h2>
<p>因变量的值由独立自变量之间的线性数学模型决定。<span class="math display">\[y=\beta_0+\beta_1\times x_1+,\cdots,+\beta_p\times x_p\]</span>,模型表示：</p>
<span class="math display">\[\begin{bmatrix}
    y_{1} \\
    y_{2} \\
    \cdots\\
    y_{n}
\end{bmatrix}\]</span>
=
<span class="math display">\[\begin{bmatrix}
    \beta_0 \\
    \beta_0 \\
    \cdots \\
    \beta_0
\end{bmatrix}\]</span>
+
<span class="math display">\[\begin{bmatrix}
    x_{11}       &amp; x_{12}  &amp; \dots &amp; x_{1p} \\
    x_{21}       &amp; x_{22}  &amp; \dots &amp; x_{2p} \\
    \cdots       &amp; \cdots  &amp; \cdots &amp; \cdots\\
    x_{n1}       &amp; x_{n2}  &amp; \dots &amp; x_{np}
\end{bmatrix}
\times
\begin{bmatrix}
    \beta_1 \\
    \beta_2 \\
    \cdots \\
    \beta_p
\end{bmatrix}\]</span>
<p>模型的矩阵表示：
<span class="math display">\[Y=X\beta\]</span></p>
<div id="模型的估计" class="section level3" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> 模型的估计</h3>
<ul>
<li>损失函数（平方和损失）：<span class="math display">\[RSS=(y-X\beta)^T(Y-X\beta)\]</span></li>
<li>数值解：<span class="math display">\[\hat{\beta}=(X^TX)^{-1}X^Ty\]</span></li>
</ul>
</div>
<div id="简单线性模型simple-linear-modelslm" class="section level3" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> 简单线性模型(Simple Linear Model,SLM)</h3>
<ul>
<li>y响应变量为连续型变量；</li>
<li>x是自变量，只包含一个变量；</li>
<li><span class="math inline">\(y_i=\beta_0 + \beta_1*x_i+\epsilon_i\)</span></li>
</ul>
<div class="sourceCode" id="cb575"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb575-1"><a href="最小二乘线性回归法.html#cb575-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb575-2"><a href="最小二乘线性回归法.html#cb575-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulated data produced</span></span>
<span id="cb575-3"><a href="最小二乘线性回归法.html#cb575-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">100</span>,<span class="dv">1</span>,<span class="dv">10</span>)</span>
<span id="cb575-4"><a href="最小二乘线性回归法.html#cb575-4" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">3</span><span class="sc">+</span><span class="dv">2</span><span class="sc">*</span>x<span class="sc">+</span><span class="fu">rnorm</span>(<span class="dv">100</span>,<span class="dv">0</span>,<span class="dv">1</span>)</span>
<span id="cb575-5"><a href="最小二乘线性回归法.html#cb575-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb575-6"><a href="最小二乘线性回归法.html#cb575-6" aria-hidden="true" tabindex="-1"></a>data_slm <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x=</span>x,<span class="at">y=</span>y)</span>
<span id="cb575-7"><a href="最小二乘线性回归法.html#cb575-7" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(data_slm)</span></code></pre></div>
<pre><code>##          x         y
## 1 3.572341  9.983366
## 2 4.126139 10.746264
## 3 2.777509  8.652261
## 4 6.973382 16.170855
## 5 6.220129 14.800695
## 6 9.919288 21.755641</code></pre>
<div class="sourceCode" id="cb577"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb577-1"><a href="最小二乘线性回归法.html#cb577-1" aria-hidden="true" tabindex="-1"></a><span class="co"># parameters estimated using ols</span></span>
<span id="cb577-2"><a href="最小二乘线性回归法.html#cb577-2" aria-hidden="true" tabindex="-1"></a>fit_slm <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span>.,<span class="at">data=</span>data_slm)</span>
<span id="cb577-3"><a href="最小二乘线性回归法.html#cb577-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit_slm)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ ., data = data_slm)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.9859 -0.6651 -0.1246  0.6495  2.7300 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.88185    0.21001   13.72   &lt;2e-16 ***
## x            2.01804    0.03656   55.19   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9167 on 98 degrees of freedom
## Multiple R-squared:  0.9688, Adjusted R-squared:  0.9685 
## F-statistic:  3046 on 1 and 98 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb579"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb579-1"><a href="最小二乘线性回归法.html#cb579-1" aria-hidden="true" tabindex="-1"></a><span class="co"># visual the model</span></span>
<span id="cb579-2"><a href="最小二乘线性回归法.html#cb579-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(data_slm,<span class="fu">aes</span>(x,y))<span class="sc">+</span><span class="fu">geom_point</span>()<span class="sc">+</span></span>
<span id="cb579-3"><a href="最小二乘线性回归法.html#cb579-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope=</span>fit_slm<span class="sc">$</span>coefficients[<span class="dv">2</span>],</span>
<span id="cb579-4"><a href="最小二乘线性回归法.html#cb579-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">intercept=</span>fit_slm<span class="sc">$</span>coefficients[<span class="dv">1</span>],</span>
<span id="cb579-5"><a href="最小二乘线性回归法.html#cb579-5" aria-hidden="true" tabindex="-1"></a>              <span class="at">color=</span><span class="st">&quot;red&quot;</span>)<span class="sc">+</span></span>
<span id="cb579-6"><a href="最小二乘线性回归法.html#cb579-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&quot;independent variable&quot;</span>,<span class="at">y=</span><span class="st">&quot;respond variable&quot;</span>,<span class="at">title=</span><span class="st">&quot;simple linear model&quot;</span>)</span></code></pre></div>
<p><img src="05-summary_files/figure-html/slm-1.png" width="672" /></p>
</div>
<div id="多元线性回归multiple-linear-modelmlm" class="section level3" number="6.2.3">
<h3><span class="header-section-number">6.2.3</span> 多元线性回归(Multiple Linear Model,mlm)</h3>
<ul>
<li>y响应变量为连续型变量；</li>
<li>x是自变量，包含多个变量（至少是2个及以上）；</li>
<li><span class="math inline">\(y_i=\beta_0 + \beta_{11}*x_{i1}+\cdots+\beta_{ip}*x_{ip}+\epsilon_i\)</span></li>
</ul>
<div class="sourceCode" id="cb580"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb580-1"><a href="最小二乘线性回归法.html#cb580-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulated data produced</span></span>
<span id="cb580-2"><a href="最小二乘线性回归法.html#cb580-2" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">100</span>,<span class="dv">1</span>,<span class="dv">10</span>)</span>
<span id="cb580-3"><a href="最小二乘线性回归法.html#cb580-3" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">100</span>,<span class="dv">1</span>,<span class="dv">10</span>)</span>
<span id="cb580-4"><a href="最小二乘线性回归法.html#cb580-4" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">*</span>x1<span class="sc">+</span><span class="dv">5</span><span class="sc">*</span>x2<span class="sc">+</span><span class="fu">rnorm</span>(<span class="dv">100</span>,<span class="dv">0</span>,<span class="dv">2</span>)</span>
<span id="cb580-5"><a href="最小二乘线性回归法.html#cb580-5" aria-hidden="true" tabindex="-1"></a>data_mlm <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x1=</span>x1,<span class="at">x2=</span>x2,<span class="at">y=</span>y)</span>
<span id="cb580-6"><a href="最小二乘线性回归法.html#cb580-6" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(data_mlm)</span></code></pre></div>
<pre><code>##         x1       x2        y
## 1 5.774988 5.044960 37.16960
## 2 1.597907 3.457927 22.37597
## 3 1.986025 6.263753 35.37145
## 4 2.220798 9.716147 53.06660
## 5 5.241381 6.662284 46.15631
## 6 1.782160 7.756305 42.07415</code></pre>
<div class="sourceCode" id="cb582"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb582-1"><a href="最小二乘线性回归法.html#cb582-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters estimated using ols</span></span>
<span id="cb582-2"><a href="最小二乘线性回归法.html#cb582-2" aria-hidden="true" tabindex="-1"></a>fit_mlm <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2,<span class="at">data=</span>data_mlm)</span>
<span id="cb582-3"><a href="最小二乘线性回归法.html#cb582-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit_mlm)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2, data = data_mlm)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.2391 -0.8618 -0.1462  1.0545  3.6340 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -0.36864    0.54337  -0.678    0.499    
## x1           2.00098    0.06800  29.428   &lt;2e-16 ***
## x2           5.04963    0.06494  77.758   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.68 on 97 degrees of freedom
## Multiple R-squared:  0.9856, Adjusted R-squared:  0.9853 
## F-statistic:  3313 on 2 and 97 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb584"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb584-1"><a href="最小二乘线性回归法.html#cb584-1" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages(&quot;plot3D&quot;)</span></span>
<span id="cb584-2"><a href="最小二乘线性回归法.html#cb584-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(plot3D)</span></code></pre></div>
<pre><code>## Warning in fun(libname, pkgname): couldn&#39;t connect to display &quot;:0&quot;</code></pre>
<div class="sourceCode" id="cb586"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb586-1"><a href="最小二乘线性回归法.html#cb586-1" aria-hidden="true" tabindex="-1"></a><span class="fu">scatter3D</span>(<span class="at">x=</span>data_mlm<span class="sc">$</span>x1,<span class="at">y=</span>data_mlm<span class="sc">$</span>x2,<span class="at">z=</span>data_mlm<span class="sc">$</span>y,<span class="at">phi =</span> <span class="dv">30</span>, <span class="at">bty =</span> <span class="st">&quot;g&quot;</span>)</span></code></pre></div>
<p><img src="05-summary_files/figure-html/mlm-1.png" width="672" /></p>
</div>
<div id="回归实例" class="section level3" number="6.2.4">
<h3><span class="header-section-number">6.2.4</span> 回归实例</h3>
<ul>
<li>使用MASS库中所带的波士顿房价数据，其中的因变量为房价的中位数，自变量为房龄、房间数等，想预测房价。</li>
</ul>
<div class="sourceCode" id="cb587"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb587-1"><a href="最小二乘线性回归法.html#cb587-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb587-2"><a href="最小二乘线性回归法.html#cb587-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb587-3"><a href="最小二乘线性回归法.html#cb587-3" aria-hidden="true" tabindex="-1"></a><span class="co">#fix(Boston)</span></span>
<span id="cb587-4"><a href="最小二乘线性回归法.html#cb587-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple linear regression model</span></span>
<span id="cb587-5"><a href="最小二乘线性回归法.html#cb587-5" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(Boston)</span></code></pre></div>
<pre><code>##  [1] &quot;crim&quot;    &quot;zn&quot;      &quot;indus&quot;   &quot;chas&quot;    &quot;nox&quot;     &quot;rm&quot;      &quot;age&quot;    
##  [8] &quot;dis&quot;     &quot;rad&quot;     &quot;tax&quot;     &quot;ptratio&quot; &quot;black&quot;   &quot;lstat&quot;   &quot;medv&quot;</code></pre>
<div class="sourceCode" id="cb589"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb589-1"><a href="最小二乘线性回归法.html#cb589-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(Boston<span class="sc">$</span>medv,Boston<span class="sc">$</span>lstat)</span></code></pre></div>
<p><img src="05-summary_files/figure-html/boslin-1.png" width="672" /></p>
<div class="sourceCode" id="cb590"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb590-1"><a href="最小二乘线性回归法.html#cb590-1" aria-hidden="true" tabindex="-1"></a>slm.fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(Boston<span class="sc">$</span>medv<span class="sc">~</span>Boston<span class="sc">$</span>lstat,<span class="at">data=</span>Boston)</span>
<span id="cb590-2"><a href="最小二乘线性回归法.html#cb590-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(slm.fit)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Boston$medv ~ Boston$lstat, data = Boston)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -15.168  -3.990  -1.318   2.034  24.500 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  34.55384    0.56263   61.41   &lt;2e-16 ***
## Boston$lstat -0.95005    0.03873  -24.53   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.216 on 504 degrees of freedom
## Multiple R-squared:  0.5441, Adjusted R-squared:  0.5432 
## F-statistic: 601.6 on 1 and 504 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb592"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb592-1"><a href="最小二乘线性回归法.html#cb592-1" aria-hidden="true" tabindex="-1"></a><span class="co"># multiple variance regression</span></span>
<span id="cb592-2"><a href="最小二乘线性回归法.html#cb592-2" aria-hidden="true" tabindex="-1"></a>mlm.fit <span class="ot">&lt;-</span> <span class="fu">lm</span>(Boston<span class="sc">$</span>medv<span class="sc">~</span>Boston<span class="sc">$</span>lstat<span class="sc">+</span>Boston<span class="sc">$</span>age,<span class="at">data=</span>Boston)</span>
<span id="cb592-3"><a href="最小二乘线性回归法.html#cb592-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mlm.fit)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Boston$medv ~ Boston$lstat + Boston$age, data = Boston)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -15.981  -3.978  -1.283   1.968  23.158 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  33.22276    0.73085  45.458  &lt; 2e-16 ***
## Boston$lstat -1.03207    0.04819 -21.416  &lt; 2e-16 ***
## Boston$age    0.03454    0.01223   2.826  0.00491 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.173 on 503 degrees of freedom
## Multiple R-squared:  0.5513, Adjusted R-squared:  0.5495 
## F-statistic:   309 on 2 and 503 DF,  p-value: &lt; 2.2e-16</code></pre>
<ul>
<li>结果解释：变量之间独立的情况下，系数就为影响程度，若存在多重共线性，则系数的解释比较复杂。</li>
</ul>
</div>
<div id="练习" class="section level3" number="6.2.5">
<h3><span class="header-section-number">6.2.5</span> 练习</h3>
<ul>
<li>例6.1</li>
</ul>

</div>
</div>
</div>
  </main>

  <div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page">
      <h2>On this page</h2>
      <div id="book-on-this-page"></div>

      <div class="book-extra">
        <ul class="list-unstyled">
          <li><a id="book-source" href="#">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="#">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
      </div>
    </nav>
  </div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5">
  <div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>数据科学导论（Introductory of Data Science）</strong>" was written by 潘蓄林. It was last built on 2022-06-08.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
<script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>

</html>
